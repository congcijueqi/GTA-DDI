{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn \n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import metrics\n",
    "\n",
    "import layers\n",
    "import models\n",
    "import custom_loss\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwj/GTA-DDI/DrugBank/data_preprocessing.py:106: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3614.)\n",
      "  return undirected_edge_list.T, features\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import DrugDataset, DrugDataLoader, TOTAL_ATOM_FEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_ATOM_FEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ddi_train = pd.read_csv('data/ddi_training.csv')\n",
    "df_ddi_val = pd.read_csv('data/ddi_test.csv')\n",
    "df_ddi_test = pd.read_csv('data/ddi_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tup = [(h, t, r) for h, t, r in zip(df_ddi_train['d1'], df_ddi_train['d2'], df_ddi_train['type'])]\n",
    "val_tup = [(h, t, r) for h, t, r in zip(df_ddi_val['d1'], df_ddi_val['d2'], df_ddi_val['type'])]\n",
    "test_tup = [(h, t, r) for h, t, r in zip(df_ddi_test['d1'], df_ddi_test['d2'], df_ddi_test['type'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115185"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38337"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38348"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6003283473184969, 0.19986449158284256, 0.19980716109866056)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(val_tup) + len(train_tup) + len(test_tup)\n",
    "len(train_tup) / total, len(test_tup)/total, len(val_tup)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_atom_feats = TOTAL_ATOM_FEATS\n",
    "n_atom_hid = 256\n",
    "rel_total = 86\n",
    "lr = 1e-2\n",
    "weight_decay = 5e-4\n",
    "n_epochs = 300\n",
    "neg_samples = 1\n",
    "batch_size = 1024\n",
    "data_size_ratio = 1\n",
    "kge_dim = 384\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DrugDataset(train_tup, ratio=data_size_ratio, neg_ent=neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = DrugDataset(val_tup, ratio=data_size_ratio, disjoint_split=False)\n",
    "test_data = DrugDataset(test_tup, disjoint_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 115185 samples, validating with 38337, and testing with 38348\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training with {len(train_data)} samples, validating with {len(val_data)}, and testing with {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DrugDataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DrugDataLoader(val_data, batch_size=batch_size *3)\n",
    "test_data_loader = DrugDataLoader(test_data, batch_size=batch_size *3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_compute(batch, device, training=True):\n",
    "        '''\n",
    "            *batch: (pos_tri, neg_tri)\n",
    "            *pos/neg_tri: (batch_h, batch_t, batch_r)\n",
    "        '''\n",
    "        probas_pred, ground_truth = [], []\n",
    "        pos_tri, neg_tri = batch\n",
    "        \n",
    "        pos_tri = [tensor.to(device=device) for tensor in pos_tri]\n",
    "        p_score = model(pos_tri)\n",
    "        probas_pred.append(torch.sigmoid(p_score.detach()).cpu())\n",
    "        ground_truth.append(np.ones(len(p_score)))\n",
    "\n",
    "        neg_tri = [tensor.to(device=device) for tensor in neg_tri]\n",
    "        n_score = model(neg_tri)\n",
    "        probas_pred.append(torch.sigmoid(n_score.detach()).cpu())\n",
    "        ground_truth.append(np.zeros(len(n_score)))\n",
    "\n",
    "        probas_pred = np.concatenate(probas_pred)\n",
    "        ground_truth = np.concatenate(ground_truth)\n",
    "\n",
    "        return p_score, n_score, probas_pred, ground_truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_compute_metrics(probas_pred, target):\n",
    "\n",
    "    pred = (probas_pred >= 0.5).astype(int)\n",
    "\n",
    "    acc = metrics.accuracy_score(target, pred)\n",
    "    auc_roc = metrics.roc_auc_score(target, probas_pred)\n",
    "    f1_score = metrics.f1_score(target, pred)\n",
    "\n",
    "    p, r, t = metrics.precision_recall_curve(target, probas_pred)\n",
    "    auc_prc = metrics.auc(r, p)\n",
    "\n",
    "    return acc, auc_roc, auc_prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data_loader, val_data_loader, loss_fn,  optimizer, n_epochs, device, scheduler=None):\n",
    "    print('Starting training at', datetime.today())\n",
    "    for i in range(1, n_epochs+1):\n",
    "        start = time.time()\n",
    "        train_loss = 0\n",
    "        train_loss_pos = 0\n",
    "        train_loss_neg = 0\n",
    "        val_loss = 0\n",
    "        val_loss_pos = 0\n",
    "        val_loss_neg = 0\n",
    "        train_probas_pred = []\n",
    "        train_ground_truth = []\n",
    "        val_probas_pred = []\n",
    "        val_ground_truth = []\n",
    "\n",
    "        for batch in train_data_loader:\n",
    "            model.train()\n",
    "            p_score, n_score, probas_pred, ground_truth = do_compute(batch, device)\n",
    "            train_probas_pred.append(probas_pred)\n",
    "            train_ground_truth.append(ground_truth)\n",
    "            loss, loss_p, loss_n = loss_fn(p_score, n_score)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * len(p_score)\n",
    "        train_loss /= len(train_data)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            train_probas_pred = np.concatenate(train_probas_pred)\n",
    "            train_ground_truth = np.concatenate(train_ground_truth)\n",
    "\n",
    "            train_acc, train_auc_roc, train_auc_prc = do_compute_metrics(train_probas_pred, train_ground_truth)\n",
    "\n",
    "            for batch in val_data_loader:\n",
    "                model.eval()\n",
    "                p_score, n_score, probas_pred, ground_truth = do_compute(batch, device)\n",
    "                val_probas_pred.append(probas_pred)\n",
    "                val_ground_truth.append(ground_truth)\n",
    "                loss, loss_p, loss_n = loss_fn(p_score, n_score)\n",
    "                val_loss += loss.item() * len(p_score)            \n",
    "\n",
    "            val_loss /= len(val_data)\n",
    "            val_probas_pred = np.concatenate(val_probas_pred)\n",
    "            val_ground_truth = np.concatenate(val_ground_truth)\n",
    "            val_acc, val_auc_roc, val_auc_prc = do_compute_metrics(val_probas_pred, val_ground_truth)\n",
    "               \n",
    "        if scheduler:\n",
    "            print('scheduling')\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        output_file = 'training_log.txt'\n",
    "\n",
    "        with open(output_file, 'a') as f:\n",
    "            # 写入第一行\n",
    "            line1 = (f'Epoch: {i} ({time.time() - start:.4f}s), train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f},'\n",
    "                    f' train_acc: {train_acc:.4f}, val_acc:{val_acc:.4f}')\n",
    "            print(line1)\n",
    "            f.write(line1 + '\\n')\n",
    "            \n",
    "            # 写入第二行\n",
    "            line2 = (f'\\t\\ttrain_roc: {train_auc_roc:.4f}, val_roc: {val_auc_roc:.4f}, train_auprc: {train_auc_prc:.4f}, val_auprc: {val_auc_prc:.4f}')\n",
    "            print(line2)\n",
    "            f.write(line2 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GTA_DDI(\n",
       "  (initial_norm): LayerNorm(55, affine=True, mode=graph)\n",
       "  (net_norms): ModuleList(\n",
       "    (0-3): 4 x LayerNorm(384, affine=True, mode=graph)\n",
       "  )\n",
       "  (block0): GTA_DDI_Block(\n",
       "    (conv): GATConv(55, 64, heads=6)\n",
       "    (readout): TopKPooling(384, ratio=0.5, multiplier=1.0)\n",
       "  )\n",
       "  (block1): GTA_DDI_Block(\n",
       "    (conv): GATConv(384, 64, heads=6)\n",
       "    (readout): TopKPooling(384, ratio=0.5, multiplier=1.0)\n",
       "  )\n",
       "  (block2): GTA_DDI_Block(\n",
       "    (conv): GATConv(384, 64, heads=6)\n",
       "    (readout): TopKPooling(384, ratio=0.5, multiplier=1.0)\n",
       "  )\n",
       "  (block3): GTA_DDI_Block(\n",
       "    (conv): GATConv(384, 64, heads=6)\n",
       "    (readout): TopKPooling(384, ratio=0.5, multiplier=1.0)\n",
       "  )\n",
       "  (co_attention): CoAttentionLayer()\n",
       "  (KGE): RESCAL(86, torch.Size([86, 147456]))\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = models.GTA_DDI(n_atom_feats, n_atom_hid, kge_dim, rel_total, heads_out_feat_params=[64, 64, 64, 64], blocks_params=[6, 6,6, 6])\n",
    "loss = custom_loss.SigmoidLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.96 ** (epoch))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(device=device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2024-06-20 13:35:18.412732\n",
      "scheduling\n",
      "Epoch: 1 (49.5570s), train_loss: 0.6736, val_loss: 0.6663, train_acc: 0.5722, val_acc:0.5825\n",
      "\t\ttrain_roc: 0.6062, val_roc: 0.6204, train_auprc: 0.5985, val_auprc: 0.6124\n",
      "scheduling\n",
      "Epoch: 2 (49.0150s), train_loss: 0.6513, val_loss: 0.6367, train_acc: 0.6129, val_acc:0.6366\n",
      "\t\ttrain_roc: 0.6589, val_roc: 0.6889, train_auprc: 0.6471, val_auprc: 0.6810\n",
      "scheduling\n",
      "Epoch: 3 (48.9937s), train_loss: 0.6199, val_loss: 0.5878, train_acc: 0.6504, val_acc:0.6820\n",
      "\t\ttrain_roc: 0.7104, val_roc: 0.7591, train_auprc: 0.6966, val_auprc: 0.7452\n",
      "scheduling\n",
      "Epoch: 4 (48.9288s), train_loss: 0.5743, val_loss: 0.6187, train_acc: 0.6951, val_acc:0.6554\n",
      "\t\ttrain_roc: 0.7661, val_roc: 0.7176, train_auprc: 0.7517, val_auprc: 0.7046\n",
      "scheduling\n",
      "Epoch: 5 (48.9575s), train_loss: 0.5613, val_loss: 0.5177, train_acc: 0.7054, val_acc:0.7386\n",
      "\t\ttrain_roc: 0.7800, val_roc: 0.8413, train_auprc: 0.7670, val_auprc: 0.8359\n",
      "scheduling\n",
      "Epoch: 6 (49.0997s), train_loss: 0.5280, val_loss: 0.4867, train_acc: 0.7322, val_acc:0.7588\n",
      "\t\ttrain_roc: 0.8114, val_roc: 0.8543, train_auprc: 0.8007, val_auprc: 0.8465\n",
      "scheduling\n",
      "Epoch: 7 (48.8872s), train_loss: 0.5160, val_loss: 0.4868, train_acc: 0.7418, val_acc:0.7643\n",
      "\t\ttrain_roc: 0.8217, val_roc: 0.8552, train_auprc: 0.8099, val_auprc: 0.8457\n",
      "scheduling\n",
      "Epoch: 8 (49.1366s), train_loss: 0.4994, val_loss: 0.5120, train_acc: 0.7544, val_acc:0.7456\n",
      "\t\ttrain_roc: 0.8353, val_roc: 0.8396, train_auprc: 0.8252, val_auprc: 0.8330\n",
      "scheduling\n",
      "Epoch: 9 (49.0730s), train_loss: 0.4788, val_loss: 0.4726, train_acc: 0.7666, val_acc:0.7734\n",
      "\t\ttrain_roc: 0.8502, val_roc: 0.8589, train_auprc: 0.8422, val_auprc: 0.8503\n",
      "scheduling\n",
      "Epoch: 10 (49.3142s), train_loss: 0.4760, val_loss: 0.4708, train_acc: 0.7715, val_acc:0.7753\n",
      "\t\ttrain_roc: 0.8531, val_roc: 0.8565, train_auprc: 0.8456, val_auprc: 0.8422\n",
      "scheduling\n",
      "Epoch: 11 (49.2338s), train_loss: 0.4454, val_loss: 0.4807, train_acc: 0.7886, val_acc:0.7701\n",
      "\t\ttrain_roc: 0.8725, val_roc: 0.8735, train_auprc: 0.8633, val_auprc: 0.8609\n",
      "scheduling\n",
      "Epoch: 12 (49.0819s), train_loss: 0.4332, val_loss: 0.4398, train_acc: 0.7957, val_acc:0.7936\n",
      "\t\ttrain_roc: 0.8798, val_roc: 0.8865, train_auprc: 0.8707, val_auprc: 0.8749\n",
      "scheduling\n",
      "Epoch: 13 (48.8663s), train_loss: 0.4317, val_loss: 0.3296, train_acc: 0.7975, val_acc:0.8623\n",
      "\t\ttrain_roc: 0.8809, val_roc: 0.9385, train_auprc: 0.8714, val_auprc: 0.9345\n",
      "scheduling\n",
      "Epoch: 14 (48.9731s), train_loss: 0.4107, val_loss: 0.3780, train_acc: 0.8100, val_acc:0.8276\n",
      "\t\ttrain_roc: 0.8929, val_roc: 0.9142, train_auprc: 0.8834, val_auprc: 0.9083\n",
      "scheduling\n",
      "Epoch: 15 (49.1759s), train_loss: 0.4001, val_loss: 0.3664, train_acc: 0.8166, val_acc:0.8385\n",
      "\t\ttrain_roc: 0.8992, val_roc: 0.9192, train_auprc: 0.8927, val_auprc: 0.9134\n",
      "scheduling\n",
      "Epoch: 16 (49.2580s), train_loss: 0.3968, val_loss: 0.3848, train_acc: 0.8175, val_acc:0.8298\n",
      "\t\ttrain_roc: 0.9006, val_roc: 0.9124, train_auprc: 0.8940, val_auprc: 0.9071\n",
      "scheduling\n",
      "Epoch: 17 (48.9056s), train_loss: 0.3918, val_loss: 0.3834, train_acc: 0.8223, val_acc:0.8290\n",
      "\t\ttrain_roc: 0.9036, val_roc: 0.9124, train_auprc: 0.8965, val_auprc: 0.9058\n",
      "scheduling\n",
      "Epoch: 18 (48.9257s), train_loss: 0.3897, val_loss: 0.4223, train_acc: 0.8229, val_acc:0.8073\n",
      "\t\ttrain_roc: 0.9043, val_roc: 0.8906, train_auprc: 0.8966, val_auprc: 0.8937\n",
      "scheduling\n",
      "Epoch: 19 (49.2305s), train_loss: 0.3913, val_loss: 0.3518, train_acc: 0.8215, val_acc:0.8488\n",
      "\t\ttrain_roc: 0.9039, val_roc: 0.9281, train_auprc: 0.8984, val_auprc: 0.9217\n",
      "scheduling\n",
      "Epoch: 20 (49.1919s), train_loss: 0.3965, val_loss: 0.4574, train_acc: 0.8179, val_acc:0.7803\n",
      "\t\ttrain_roc: 0.9008, val_roc: 0.9086, train_auprc: 0.8936, val_auprc: 0.9021\n",
      "scheduling\n",
      "Epoch: 21 (49.4614s), train_loss: 0.4111, val_loss: 0.4250, train_acc: 0.8105, val_acc:0.8007\n",
      "\t\ttrain_roc: 0.8931, val_roc: 0.8948, train_auprc: 0.8861, val_auprc: 0.8870\n",
      "scheduling\n",
      "Epoch: 22 (49.1684s), train_loss: 0.3664, val_loss: 0.3578, train_acc: 0.8357, val_acc:0.8363\n",
      "\t\ttrain_roc: 0.9164, val_roc: 0.9402, train_auprc: 0.9114, val_auprc: 0.9341\n",
      "scheduling\n",
      "Epoch: 23 (49.0605s), train_loss: 0.3605, val_loss: 0.3166, train_acc: 0.8384, val_acc:0.8678\n",
      "\t\ttrain_roc: 0.9189, val_roc: 0.9439, train_auprc: 0.9137, val_auprc: 0.9389\n",
      "scheduling\n",
      "Epoch: 24 (49.1427s), train_loss: 0.3246, val_loss: 0.2597, train_acc: 0.8599, val_acc:0.8933\n",
      "\t\ttrain_roc: 0.9352, val_roc: 0.9612, train_auprc: 0.9307, val_auprc: 0.9590\n",
      "scheduling\n",
      "Epoch: 25 (49.1343s), train_loss: 0.3519, val_loss: 0.3453, train_acc: 0.8439, val_acc:0.8495\n",
      "\t\ttrain_roc: 0.9230, val_roc: 0.9348, train_auprc: 0.9178, val_auprc: 0.9288\n",
      "scheduling\n",
      "Epoch: 26 (49.0066s), train_loss: 0.3637, val_loss: 0.3174, train_acc: 0.8362, val_acc:0.8622\n",
      "\t\ttrain_roc: 0.9174, val_roc: 0.9420, train_auprc: 0.9118, val_auprc: 0.9371\n",
      "scheduling\n",
      "Epoch: 27 (48.8412s), train_loss: 0.3490, val_loss: 0.3296, train_acc: 0.8457, val_acc:0.8507\n",
      "\t\ttrain_roc: 0.9244, val_roc: 0.9485, train_auprc: 0.9189, val_auprc: 0.9448\n",
      "scheduling\n",
      "Epoch: 28 (49.0449s), train_loss: 0.3451, val_loss: 0.3496, train_acc: 0.8478, val_acc:0.8395\n",
      "\t\ttrain_roc: 0.9261, val_roc: 0.9327, train_auprc: 0.9204, val_auprc: 0.9285\n",
      "scheduling\n",
      "Epoch: 29 (49.0410s), train_loss: 0.3458, val_loss: 0.2908, train_acc: 0.8481, val_acc:0.8773\n",
      "\t\ttrain_roc: 0.9260, val_roc: 0.9512, train_auprc: 0.9213, val_auprc: 0.9481\n",
      "scheduling\n",
      "Epoch: 30 (48.9323s), train_loss: 0.3382, val_loss: 0.2851, train_acc: 0.8505, val_acc:0.8790\n",
      "\t\ttrain_roc: 0.9294, val_roc: 0.9526, train_auprc: 0.9263, val_auprc: 0.9518\n",
      "scheduling\n",
      "Epoch: 31 (48.9107s), train_loss: 0.3058, val_loss: 0.2877, train_acc: 0.8685, val_acc:0.8785\n",
      "\t\ttrain_roc: 0.9427, val_roc: 0.9557, train_auprc: 0.9404, val_auprc: 0.9524\n",
      "scheduling\n",
      "Epoch: 32 (48.8527s), train_loss: 0.3188, val_loss: 0.3089, train_acc: 0.8613, val_acc:0.8741\n",
      "\t\ttrain_roc: 0.9374, val_roc: 0.9482, train_auprc: 0.9329, val_auprc: 0.9460\n",
      "scheduling\n",
      "Epoch: 33 (48.9934s), train_loss: 0.3124, val_loss: 0.2387, train_acc: 0.8640, val_acc:0.9021\n",
      "\t\ttrain_roc: 0.9401, val_roc: 0.9671, train_auprc: 0.9376, val_auprc: 0.9654\n",
      "scheduling\n",
      "Epoch: 34 (49.1202s), train_loss: 0.3005, val_loss: 0.3558, train_acc: 0.8714, val_acc:0.8381\n",
      "\t\ttrain_roc: 0.9448, val_roc: 0.9475, train_auprc: 0.9431, val_auprc: 0.9458\n",
      "scheduling\n",
      "Epoch: 35 (48.8795s), train_loss: 0.3238, val_loss: 0.2496, train_acc: 0.8581, val_acc:0.8960\n",
      "\t\ttrain_roc: 0.9354, val_roc: 0.9637, train_auprc: 0.9314, val_auprc: 0.9613\n",
      "scheduling\n",
      "Epoch: 36 (48.7597s), train_loss: 0.2776, val_loss: 0.2684, train_acc: 0.8828, val_acc:0.8839\n",
      "\t\ttrain_roc: 0.9527, val_roc: 0.9689, train_auprc: 0.9488, val_auprc: 0.9669\n",
      "scheduling\n",
      "Epoch: 37 (48.8086s), train_loss: 0.2735, val_loss: 0.2722, train_acc: 0.8848, val_acc:0.8857\n",
      "\t\ttrain_roc: 0.9542, val_roc: 0.9558, train_auprc: 0.9510, val_auprc: 0.9533\n",
      "scheduling\n",
      "Epoch: 38 (48.5322s), train_loss: 0.2998, val_loss: 0.2691, train_acc: 0.8707, val_acc:0.8850\n",
      "\t\ttrain_roc: 0.9449, val_roc: 0.9604, train_auprc: 0.9421, val_auprc: 0.9616\n",
      "scheduling\n",
      "Epoch: 39 (48.4501s), train_loss: 0.2769, val_loss: 0.2370, train_acc: 0.8828, val_acc:0.9035\n",
      "\t\ttrain_roc: 0.9531, val_roc: 0.9708, train_auprc: 0.9498, val_auprc: 0.9696\n",
      "scheduling\n",
      "Epoch: 40 (48.6770s), train_loss: 0.2522, val_loss: 0.2110, train_acc: 0.8937, val_acc:0.9174\n",
      "\t\ttrain_roc: 0.9611, val_roc: 0.9753, train_auprc: 0.9593, val_auprc: 0.9747\n",
      "scheduling\n",
      "Epoch: 41 (48.6006s), train_loss: 0.2480, val_loss: 0.2817, train_acc: 0.8964, val_acc:0.8771\n",
      "\t\ttrain_roc: 0.9624, val_roc: 0.9648, train_auprc: 0.9599, val_auprc: 0.9646\n",
      "scheduling\n",
      "Epoch: 42 (48.4759s), train_loss: 0.2429, val_loss: 0.2211, train_acc: 0.8980, val_acc:0.9094\n",
      "\t\ttrain_roc: 0.9639, val_roc: 0.9714, train_auprc: 0.9618, val_auprc: 0.9697\n",
      "scheduling\n",
      "Epoch: 43 (48.5709s), train_loss: 0.2601, val_loss: 0.1989, train_acc: 0.8902, val_acc:0.9213\n",
      "\t\ttrain_roc: 0.9585, val_roc: 0.9786, train_auprc: 0.9559, val_auprc: 0.9773\n",
      "scheduling\n",
      "Epoch: 44 (48.4175s), train_loss: 0.2494, val_loss: 0.2187, train_acc: 0.8959, val_acc:0.9140\n",
      "\t\ttrain_roc: 0.9619, val_roc: 0.9739, train_auprc: 0.9595, val_auprc: 0.9722\n",
      "scheduling\n",
      "Epoch: 45 (48.6700s), train_loss: 0.2407, val_loss: 0.2078, train_acc: 0.8999, val_acc:0.9169\n",
      "\t\ttrain_roc: 0.9647, val_roc: 0.9743, train_auprc: 0.9631, val_auprc: 0.9735\n",
      "scheduling\n",
      "Epoch: 46 (48.7445s), train_loss: 0.2530, val_loss: 0.2171, train_acc: 0.8948, val_acc:0.9096\n",
      "\t\ttrain_roc: 0.9609, val_roc: 0.9748, train_auprc: 0.9583, val_auprc: 0.9745\n",
      "scheduling\n",
      "Epoch: 47 (48.6781s), train_loss: 0.2256, val_loss: 0.1927, train_acc: 0.9068, val_acc:0.9210\n",
      "\t\ttrain_roc: 0.9688, val_roc: 0.9789, train_auprc: 0.9667, val_auprc: 0.9783\n",
      "scheduling\n",
      "Epoch: 48 (48.5623s), train_loss: 0.2549, val_loss: 0.2103, train_acc: 0.8932, val_acc:0.9185\n",
      "\t\ttrain_roc: 0.9602, val_roc: 0.9758, train_auprc: 0.9580, val_auprc: 0.9755\n",
      "scheduling\n",
      "Epoch: 49 (48.5376s), train_loss: 0.2275, val_loss: 0.1949, train_acc: 0.9070, val_acc:0.9228\n",
      "\t\ttrain_roc: 0.9686, val_roc: 0.9823, train_auprc: 0.9676, val_auprc: 0.9814\n",
      "scheduling\n",
      "Epoch: 50 (48.6518s), train_loss: 0.2318, val_loss: 0.1795, train_acc: 0.9042, val_acc:0.9305\n",
      "\t\ttrain_roc: 0.9671, val_roc: 0.9836, train_auprc: 0.9652, val_auprc: 0.9826\n",
      "scheduling\n",
      "Epoch: 51 (48.7084s), train_loss: 0.2268, val_loss: 0.1883, train_acc: 0.9066, val_acc:0.9238\n",
      "\t\ttrain_roc: 0.9687, val_roc: 0.9818, train_auprc: 0.9671, val_auprc: 0.9813\n",
      "scheduling\n",
      "Epoch: 52 (48.9713s), train_loss: 0.2245, val_loss: 0.2113, train_acc: 0.9073, val_acc:0.9119\n",
      "\t\ttrain_roc: 0.9692, val_roc: 0.9825, train_auprc: 0.9676, val_auprc: 0.9815\n",
      "scheduling\n",
      "Epoch: 53 (48.6126s), train_loss: 0.2139, val_loss: 0.1835, train_acc: 0.9120, val_acc:0.9289\n",
      "\t\ttrain_roc: 0.9720, val_roc: 0.9810, train_auprc: 0.9703, val_auprc: 0.9807\n",
      "scheduling\n",
      "Epoch: 54 (48.6389s), train_loss: 0.2230, val_loss: 0.1848, train_acc: 0.9079, val_acc:0.9289\n",
      "\t\ttrain_roc: 0.9696, val_roc: 0.9811, train_auprc: 0.9679, val_auprc: 0.9809\n",
      "scheduling\n",
      "Epoch: 55 (48.7993s), train_loss: 0.2039, val_loss: 0.1895, train_acc: 0.9170, val_acc:0.9220\n",
      "\t\ttrain_roc: 0.9745, val_roc: 0.9831, train_auprc: 0.9729, val_auprc: 0.9825\n",
      "scheduling\n",
      "Epoch: 56 (48.5689s), train_loss: 0.2204, val_loss: 0.1727, train_acc: 0.9084, val_acc:0.9343\n",
      "\t\ttrain_roc: 0.9703, val_roc: 0.9837, train_auprc: 0.9693, val_auprc: 0.9832\n",
      "scheduling\n",
      "Epoch: 57 (48.5792s), train_loss: 0.2136, val_loss: 0.1992, train_acc: 0.9133, val_acc:0.9200\n",
      "\t\ttrain_roc: 0.9721, val_roc: 0.9765, train_auprc: 0.9704, val_auprc: 0.9758\n",
      "scheduling\n",
      "Epoch: 58 (48.6675s), train_loss: 0.2258, val_loss: 0.1954, train_acc: 0.9062, val_acc:0.9208\n",
      "\t\ttrain_roc: 0.9687, val_roc: 0.9808, train_auprc: 0.9667, val_auprc: 0.9800\n",
      "scheduling\n",
      "Epoch: 59 (48.6033s), train_loss: 0.1971, val_loss: 0.1704, train_acc: 0.9203, val_acc:0.9325\n",
      "\t\ttrain_roc: 0.9763, val_roc: 0.9828, train_auprc: 0.9749, val_auprc: 0.9818\n",
      "scheduling\n",
      "Epoch: 60 (48.4675s), train_loss: 0.2083, val_loss: 0.1964, train_acc: 0.9147, val_acc:0.9223\n",
      "\t\ttrain_roc: 0.9734, val_roc: 0.9790, train_auprc: 0.9721, val_auprc: 0.9779\n",
      "scheduling\n",
      "Epoch: 61 (48.7117s), train_loss: 0.2023, val_loss: 0.1668, train_acc: 0.9187, val_acc:0.9350\n",
      "\t\ttrain_roc: 0.9751, val_roc: 0.9838, train_auprc: 0.9737, val_auprc: 0.9835\n",
      "scheduling\n",
      "Epoch: 62 (48.9962s), train_loss: 0.2077, val_loss: 0.1608, train_acc: 0.9147, val_acc:0.9389\n",
      "\t\ttrain_roc: 0.9737, val_roc: 0.9851, train_auprc: 0.9724, val_auprc: 0.9846\n",
      "scheduling\n",
      "Epoch: 63 (48.8268s), train_loss: 0.2004, val_loss: 0.2122, train_acc: 0.9193, val_acc:0.9116\n",
      "\t\ttrain_roc: 0.9755, val_roc: 0.9836, train_auprc: 0.9739, val_auprc: 0.9825\n",
      "scheduling\n",
      "Epoch: 64 (48.8995s), train_loss: 0.1981, val_loss: 0.1456, train_acc: 0.9206, val_acc:0.9454\n",
      "\t\ttrain_roc: 0.9760, val_roc: 0.9881, train_auprc: 0.9744, val_auprc: 0.9875\n",
      "scheduling\n",
      "Epoch: 65 (48.5618s), train_loss: 0.1889, val_loss: 0.1535, train_acc: 0.9245, val_acc:0.9411\n",
      "\t\ttrain_roc: 0.9781, val_roc: 0.9865, train_auprc: 0.9767, val_auprc: 0.9861\n",
      "scheduling\n",
      "Epoch: 66 (48.6650s), train_loss: 0.1861, val_loss: 0.1656, train_acc: 0.9254, val_acc:0.9343\n",
      "\t\ttrain_roc: 0.9789, val_roc: 0.9870, train_auprc: 0.9781, val_auprc: 0.9865\n",
      "scheduling\n",
      "Epoch: 67 (48.7041s), train_loss: 0.1719, val_loss: 0.1584, train_acc: 0.9327, val_acc:0.9373\n",
      "\t\ttrain_roc: 0.9820, val_roc: 0.9859, train_auprc: 0.9812, val_auprc: 0.9857\n",
      "scheduling\n",
      "Epoch: 68 (48.7093s), train_loss: 0.1753, val_loss: 0.1382, train_acc: 0.9301, val_acc:0.9477\n",
      "\t\ttrain_roc: 0.9812, val_roc: 0.9891, train_auprc: 0.9805, val_auprc: 0.9887\n",
      "scheduling\n",
      "Epoch: 69 (48.5948s), train_loss: 0.1749, val_loss: 0.1506, train_acc: 0.9307, val_acc:0.9416\n",
      "\t\ttrain_roc: 0.9814, val_roc: 0.9886, train_auprc: 0.9808, val_auprc: 0.9884\n",
      "scheduling\n",
      "Epoch: 70 (48.6689s), train_loss: 0.1724, val_loss: 0.1464, train_acc: 0.9318, val_acc:0.9444\n",
      "\t\ttrain_roc: 0.9818, val_roc: 0.9881, train_auprc: 0.9811, val_auprc: 0.9878\n",
      "scheduling\n",
      "Epoch: 71 (48.5249s), train_loss: 0.1715, val_loss: 0.1553, train_acc: 0.9326, val_acc:0.9386\n",
      "\t\ttrain_roc: 0.9820, val_roc: 0.9891, train_auprc: 0.9813, val_auprc: 0.9888\n",
      "scheduling\n",
      "Epoch: 72 (48.7281s), train_loss: 0.1692, val_loss: 0.1598, train_acc: 0.9330, val_acc:0.9372\n",
      "\t\ttrain_roc: 0.9825, val_roc: 0.9862, train_auprc: 0.9816, val_auprc: 0.9859\n",
      "scheduling\n",
      "Epoch: 73 (48.8564s), train_loss: 0.1753, val_loss: 0.1323, train_acc: 0.9303, val_acc:0.9501\n",
      "\t\ttrain_roc: 0.9811, val_roc: 0.9902, train_auprc: 0.9801, val_auprc: 0.9903\n",
      "scheduling\n",
      "Epoch: 74 (48.8050s), train_loss: 0.1662, val_loss: 0.1424, train_acc: 0.9342, val_acc:0.9466\n",
      "\t\ttrain_roc: 0.9832, val_roc: 0.9884, train_auprc: 0.9828, val_auprc: 0.9882\n",
      "scheduling\n",
      "Epoch: 75 (48.7816s), train_loss: 0.2011, val_loss: 0.1652, train_acc: 0.9175, val_acc:0.9370\n",
      "\t\ttrain_roc: 0.9754, val_roc: 0.9848, train_auprc: 0.9751, val_auprc: 0.9841\n",
      "scheduling\n",
      "Epoch: 76 (48.6836s), train_loss: 0.1913, val_loss: 0.1597, train_acc: 0.9236, val_acc:0.9399\n",
      "\t\ttrain_roc: 0.9777, val_roc: 0.9855, train_auprc: 0.9770, val_auprc: 0.9853\n",
      "scheduling\n",
      "Epoch: 77 (48.8560s), train_loss: 0.1858, val_loss: 0.1684, train_acc: 0.9251, val_acc:0.9333\n",
      "\t\ttrain_roc: 0.9790, val_roc: 0.9841, train_auprc: 0.9782, val_auprc: 0.9840\n",
      "scheduling\n",
      "Epoch: 78 (48.7707s), train_loss: 0.1878, val_loss: 0.1901, train_acc: 0.9249, val_acc:0.9238\n",
      "\t\ttrain_roc: 0.9785, val_roc: 0.9818, train_auprc: 0.9775, val_auprc: 0.9817\n",
      "scheduling\n",
      "Epoch: 79 (48.7819s), train_loss: 0.1807, val_loss: 0.1558, train_acc: 0.9274, val_acc:0.9394\n",
      "\t\ttrain_roc: 0.9803, val_roc: 0.9865, train_auprc: 0.9796, val_auprc: 0.9863\n",
      "scheduling\n",
      "Epoch: 80 (48.7558s), train_loss: 0.1792, val_loss: 0.1705, train_acc: 0.9289, val_acc:0.9323\n",
      "\t\ttrain_roc: 0.9804, val_roc: 0.9861, train_auprc: 0.9798, val_auprc: 0.9861\n",
      "scheduling\n",
      "Epoch: 81 (48.5062s), train_loss: 0.1668, val_loss: 0.1587, train_acc: 0.9345, val_acc:0.9370\n",
      "\t\ttrain_roc: 0.9833, val_roc: 0.9858, train_auprc: 0.9827, val_auprc: 0.9859\n",
      "scheduling\n",
      "Epoch: 82 (49.1719s), train_loss: 0.1818, val_loss: 0.1648, train_acc: 0.9283, val_acc:0.9367\n",
      "\t\ttrain_roc: 0.9797, val_roc: 0.9850, train_auprc: 0.9787, val_auprc: 0.9845\n",
      "scheduling\n",
      "Epoch: 83 (48.7283s), train_loss: 0.1774, val_loss: 0.1590, train_acc: 0.9301, val_acc:0.9399\n",
      "\t\ttrain_roc: 0.9808, val_roc: 0.9869, train_auprc: 0.9799, val_auprc: 0.9868\n",
      "scheduling\n",
      "Epoch: 84 (48.5763s), train_loss: 0.1836, val_loss: 0.1607, train_acc: 0.9259, val_acc:0.9386\n",
      "\t\ttrain_roc: 0.9794, val_roc: 0.9847, train_auprc: 0.9783, val_auprc: 0.9842\n",
      "scheduling\n",
      "Epoch: 85 (48.6495s), train_loss: 0.1767, val_loss: 0.1598, train_acc: 0.9305, val_acc:0.9391\n",
      "\t\ttrain_roc: 0.9810, val_roc: 0.9854, train_auprc: 0.9804, val_auprc: 0.9853\n",
      "scheduling\n",
      "Epoch: 86 (48.6608s), train_loss: 0.1701, val_loss: 0.1696, train_acc: 0.9324, val_acc:0.9327\n",
      "\t\ttrain_roc: 0.9825, val_roc: 0.9858, train_auprc: 0.9819, val_auprc: 0.9859\n",
      "scheduling\n",
      "Epoch: 87 (48.5500s), train_loss: 0.1650, val_loss: 0.1440, train_acc: 0.9352, val_acc:0.9455\n",
      "\t\ttrain_roc: 0.9835, val_roc: 0.9884, train_auprc: 0.9829, val_auprc: 0.9882\n",
      "scheduling\n",
      "Epoch: 88 (48.0810s), train_loss: 0.1721, val_loss: 0.1339, train_acc: 0.9311, val_acc:0.9499\n",
      "\t\ttrain_roc: 0.9819, val_roc: 0.9899, train_auprc: 0.9812, val_auprc: 0.9897\n",
      "scheduling\n",
      "Epoch: 89 (47.7156s), train_loss: 0.1710, val_loss: 0.1234, train_acc: 0.9320, val_acc:0.9560\n",
      "\t\ttrain_roc: 0.9822, val_roc: 0.9914, train_auprc: 0.9814, val_auprc: 0.9913\n",
      "scheduling\n",
      "Epoch: 90 (47.8651s), train_loss: 0.1594, val_loss: 0.1431, train_acc: 0.9377, val_acc:0.9459\n",
      "\t\ttrain_roc: 0.9845, val_roc: 0.9897, train_auprc: 0.9838, val_auprc: 0.9895\n",
      "scheduling\n",
      "Epoch: 91 (48.0304s), train_loss: 0.1539, val_loss: 0.1309, train_acc: 0.9399, val_acc:0.9517\n",
      "\t\ttrain_roc: 0.9855, val_roc: 0.9907, train_auprc: 0.9847, val_auprc: 0.9907\n",
      "scheduling\n",
      "Epoch: 92 (48.0454s), train_loss: 0.1603, val_loss: 0.1417, train_acc: 0.9376, val_acc:0.9463\n",
      "\t\ttrain_roc: 0.9843, val_roc: 0.9885, train_auprc: 0.9838, val_auprc: 0.9882\n",
      "scheduling\n",
      "Epoch: 93 (48.0854s), train_loss: 0.1505, val_loss: 0.1339, train_acc: 0.9417, val_acc:0.9483\n",
      "\t\ttrain_roc: 0.9863, val_roc: 0.9901, train_auprc: 0.9855, val_auprc: 0.9898\n",
      "scheduling\n",
      "Epoch: 94 (48.0914s), train_loss: 0.1584, val_loss: 0.1457, train_acc: 0.9377, val_acc:0.9441\n",
      "\t\ttrain_roc: 0.9847, val_roc: 0.9881, train_auprc: 0.9839, val_auprc: 0.9881\n",
      "scheduling\n",
      "Epoch: 95 (48.0270s), train_loss: 0.1627, val_loss: 0.1448, train_acc: 0.9360, val_acc:0.9453\n",
      "\t\ttrain_roc: 0.9837, val_roc: 0.9879, train_auprc: 0.9828, val_auprc: 0.9878\n",
      "scheduling\n",
      "Epoch: 96 (48.0818s), train_loss: 0.1667, val_loss: 0.1478, train_acc: 0.9342, val_acc:0.9431\n",
      "\t\ttrain_roc: 0.9829, val_roc: 0.9900, train_auprc: 0.9819, val_auprc: 0.9898\n",
      "scheduling\n",
      "Epoch: 97 (48.0575s), train_loss: 0.1607, val_loss: 0.1321, train_acc: 0.9369, val_acc:0.9517\n",
      "\t\ttrain_roc: 0.9842, val_roc: 0.9902, train_auprc: 0.9834, val_auprc: 0.9901\n",
      "scheduling\n",
      "Epoch: 98 (48.0382s), train_loss: 0.1727, val_loss: 0.1534, train_acc: 0.9319, val_acc:0.9415\n",
      "\t\ttrain_roc: 0.9816, val_roc: 0.9887, train_auprc: 0.9803, val_auprc: 0.9883\n",
      "scheduling\n",
      "Epoch: 99 (48.0250s), train_loss: 0.1695, val_loss: 0.1550, train_acc: 0.9339, val_acc:0.9402\n",
      "\t\ttrain_roc: 0.9824, val_roc: 0.9874, train_auprc: 0.9810, val_auprc: 0.9872\n",
      "scheduling\n",
      "Epoch: 100 (48.0216s), train_loss: 0.1602, val_loss: 0.1522, train_acc: 0.9377, val_acc:0.9410\n",
      "\t\ttrain_roc: 0.9844, val_roc: 0.9883, train_auprc: 0.9836, val_auprc: 0.9882\n",
      "scheduling\n",
      "Epoch: 101 (48.0766s), train_loss: 0.1652, val_loss: 0.1307, train_acc: 0.9357, val_acc:0.9518\n",
      "\t\ttrain_roc: 0.9833, val_roc: 0.9901, train_auprc: 0.9827, val_auprc: 0.9898\n",
      "scheduling\n",
      "Epoch: 102 (48.1007s), train_loss: 0.1503, val_loss: 0.1201, train_acc: 0.9429, val_acc:0.9558\n",
      "\t\ttrain_roc: 0.9862, val_roc: 0.9917, train_auprc: 0.9851, val_auprc: 0.9917\n",
      "scheduling\n",
      "Epoch: 103 (48.0548s), train_loss: 0.1543, val_loss: 0.1490, train_acc: 0.9400, val_acc:0.9423\n",
      "\t\ttrain_roc: 0.9854, val_roc: 0.9897, train_auprc: 0.9845, val_auprc: 0.9892\n",
      "scheduling\n",
      "Epoch: 104 (48.0484s), train_loss: 0.1387, val_loss: 0.1383, train_acc: 0.9466, val_acc:0.9475\n",
      "\t\ttrain_roc: 0.9884, val_roc: 0.9886, train_auprc: 0.9880, val_auprc: 0.9887\n",
      "scheduling\n",
      "Epoch: 105 (48.0532s), train_loss: 0.1524, val_loss: 0.1217, train_acc: 0.9407, val_acc:0.9554\n",
      "\t\ttrain_roc: 0.9858, val_roc: 0.9914, train_auprc: 0.9851, val_auprc: 0.9914\n",
      "scheduling\n",
      "Epoch: 106 (48.0519s), train_loss: 0.1527, val_loss: 0.1347, train_acc: 0.9407, val_acc:0.9500\n",
      "\t\ttrain_roc: 0.9858, val_roc: 0.9913, train_auprc: 0.9853, val_auprc: 0.9913\n",
      "scheduling\n",
      "Epoch: 107 (48.0857s), train_loss: 0.1508, val_loss: 0.1399, train_acc: 0.9409, val_acc:0.9463\n",
      "\t\ttrain_roc: 0.9862, val_roc: 0.9920, train_auprc: 0.9857, val_auprc: 0.9917\n",
      "scheduling\n",
      "Epoch: 108 (48.0231s), train_loss: 0.1611, val_loss: 0.1259, train_acc: 0.9367, val_acc:0.9544\n",
      "\t\ttrain_roc: 0.9840, val_roc: 0.9917, train_auprc: 0.9834, val_auprc: 0.9916\n",
      "scheduling\n",
      "Epoch: 109 (48.0923s), train_loss: 0.1422, val_loss: 0.1156, train_acc: 0.9450, val_acc:0.9587\n",
      "\t\ttrain_roc: 0.9877, val_roc: 0.9924, train_auprc: 0.9871, val_auprc: 0.9925\n",
      "scheduling\n",
      "Epoch: 110 (48.0654s), train_loss: 0.1612, val_loss: 0.1289, train_acc: 0.9372, val_acc:0.9533\n",
      "\t\ttrain_roc: 0.9840, val_roc: 0.9909, train_auprc: 0.9829, val_auprc: 0.9909\n",
      "scheduling\n",
      "Epoch: 111 (48.0815s), train_loss: 0.1478, val_loss: 0.1179, train_acc: 0.9433, val_acc:0.9574\n",
      "\t\ttrain_roc: 0.9867, val_roc: 0.9920, train_auprc: 0.9863, val_auprc: 0.9921\n",
      "scheduling\n",
      "Epoch: 112 (48.0453s), train_loss: 0.1458, val_loss: 0.1177, train_acc: 0.9434, val_acc:0.9577\n",
      "\t\ttrain_roc: 0.9871, val_roc: 0.9919, train_auprc: 0.9866, val_auprc: 0.9920\n",
      "scheduling\n",
      "Epoch: 113 (48.0701s), train_loss: 0.1496, val_loss: 0.1274, train_acc: 0.9419, val_acc:0.9541\n",
      "\t\ttrain_roc: 0.9863, val_roc: 0.9903, train_auprc: 0.9861, val_auprc: 0.9903\n",
      "scheduling\n",
      "Epoch: 114 (48.0659s), train_loss: 0.1558, val_loss: 0.1218, train_acc: 0.9390, val_acc:0.9550\n",
      "\t\ttrain_roc: 0.9850, val_roc: 0.9914, train_auprc: 0.9842, val_auprc: 0.9915\n",
      "scheduling\n",
      "Epoch: 115 (48.1149s), train_loss: 0.1585, val_loss: 0.1193, train_acc: 0.9381, val_acc:0.9565\n",
      "\t\ttrain_roc: 0.9847, val_roc: 0.9918, train_auprc: 0.9843, val_auprc: 0.9920\n",
      "scheduling\n",
      "Epoch: 116 (48.0439s), train_loss: 0.1441, val_loss: 0.1245, train_acc: 0.9444, val_acc:0.9545\n",
      "\t\ttrain_roc: 0.9875, val_roc: 0.9911, train_auprc: 0.9871, val_auprc: 0.9910\n",
      "scheduling\n",
      "Epoch: 117 (48.0574s), train_loss: 0.1504, val_loss: 0.1164, train_acc: 0.9418, val_acc:0.9585\n",
      "\t\ttrain_roc: 0.9862, val_roc: 0.9925, train_auprc: 0.9858, val_auprc: 0.9928\n",
      "scheduling\n",
      "Epoch: 118 (48.0756s), train_loss: 0.1483, val_loss: 0.1234, train_acc: 0.9428, val_acc:0.9555\n",
      "\t\ttrain_roc: 0.9867, val_roc: 0.9912, train_auprc: 0.9864, val_auprc: 0.9914\n",
      "scheduling\n",
      "Epoch: 119 (48.0693s), train_loss: 0.1378, val_loss: 0.1334, train_acc: 0.9474, val_acc:0.9501\n",
      "\t\ttrain_roc: 0.9886, val_roc: 0.9902, train_auprc: 0.9882, val_auprc: 0.9903\n",
      "scheduling\n",
      "Epoch: 120 (48.0276s), train_loss: 0.1444, val_loss: 0.1226, train_acc: 0.9449, val_acc:0.9561\n",
      "\t\ttrain_roc: 0.9873, val_roc: 0.9914, train_auprc: 0.9865, val_auprc: 0.9915\n",
      "scheduling\n",
      "Epoch: 121 (48.0289s), train_loss: 0.1528, val_loss: 0.1370, train_acc: 0.9400, val_acc:0.9490\n",
      "\t\ttrain_roc: 0.9858, val_roc: 0.9905, train_auprc: 0.9854, val_auprc: 0.9907\n",
      "scheduling\n",
      "Epoch: 122 (48.0817s), train_loss: 0.1406, val_loss: 0.1302, train_acc: 0.9459, val_acc:0.9508\n",
      "\t\ttrain_roc: 0.9881, val_roc: 0.9903, train_auprc: 0.9877, val_auprc: 0.9904\n",
      "scheduling\n",
      "Epoch: 123 (48.0390s), train_loss: 0.1539, val_loss: 0.1269, train_acc: 0.9404, val_acc:0.9535\n",
      "\t\ttrain_roc: 0.9856, val_roc: 0.9906, train_auprc: 0.9850, val_auprc: 0.9907\n",
      "scheduling\n",
      "Epoch: 124 (48.0433s), train_loss: 0.1431, val_loss: 0.1363, train_acc: 0.9444, val_acc:0.9496\n",
      "\t\ttrain_roc: 0.9877, val_roc: 0.9897, train_auprc: 0.9875, val_auprc: 0.9897\n",
      "scheduling\n",
      "Epoch: 125 (48.0350s), train_loss: 0.1480, val_loss: 0.1212, train_acc: 0.9424, val_acc:0.9560\n",
      "\t\ttrain_roc: 0.9867, val_roc: 0.9915, train_auprc: 0.9863, val_auprc: 0.9916\n",
      "scheduling\n",
      "Epoch: 126 (48.0616s), train_loss: 0.1447, val_loss: 0.1253, train_acc: 0.9437, val_acc:0.9538\n",
      "\t\ttrain_roc: 0.9874, val_roc: 0.9908, train_auprc: 0.9871, val_auprc: 0.9911\n",
      "scheduling\n",
      "Epoch: 127 (48.0485s), train_loss: 0.1503, val_loss: 0.1310, train_acc: 0.9411, val_acc:0.9511\n",
      "\t\ttrain_roc: 0.9862, val_roc: 0.9900, train_auprc: 0.9856, val_auprc: 0.9902\n",
      "scheduling\n",
      "Epoch: 128 (48.0073s), train_loss: 0.1381, val_loss: 0.1323, train_acc: 0.9462, val_acc:0.9509\n",
      "\t\ttrain_roc: 0.9886, val_roc: 0.9902, train_auprc: 0.9883, val_auprc: 0.9906\n",
      "scheduling\n",
      "Epoch: 129 (47.9335s), train_loss: 0.1379, val_loss: 0.1332, train_acc: 0.9466, val_acc:0.9495\n",
      "\t\ttrain_roc: 0.9886, val_roc: 0.9897, train_auprc: 0.9882, val_auprc: 0.9900\n",
      "scheduling\n",
      "Epoch: 130 (47.9808s), train_loss: 0.1392, val_loss: 0.1150, train_acc: 0.9460, val_acc:0.9585\n",
      "\t\ttrain_roc: 0.9883, val_roc: 0.9935, train_auprc: 0.9882, val_auprc: 0.9938\n",
      "scheduling\n",
      "Epoch: 131 (47.9878s), train_loss: 0.1539, val_loss: 0.1182, train_acc: 0.9406, val_acc:0.9560\n",
      "\t\ttrain_roc: 0.9854, val_roc: 0.9920, train_auprc: 0.9849, val_auprc: 0.9923\n",
      "scheduling\n",
      "Epoch: 132 (48.0503s), train_loss: 0.1306, val_loss: 0.1164, train_acc: 0.9505, val_acc:0.9584\n",
      "\t\ttrain_roc: 0.9898, val_roc: 0.9921, train_auprc: 0.9894, val_auprc: 0.9923\n",
      "scheduling\n",
      "Epoch: 133 (48.0502s), train_loss: 0.1317, val_loss: 0.1141, train_acc: 0.9494, val_acc:0.9600\n",
      "\t\ttrain_roc: 0.9896, val_roc: 0.9927, train_auprc: 0.9894, val_auprc: 0.9930\n",
      "scheduling\n",
      "Epoch: 134 (48.0643s), train_loss: 0.1378, val_loss: 0.1149, train_acc: 0.9477, val_acc:0.9596\n",
      "\t\ttrain_roc: 0.9885, val_roc: 0.9925, train_auprc: 0.9885, val_auprc: 0.9928\n",
      "scheduling\n",
      "Epoch: 135 (48.0132s), train_loss: 0.1340, val_loss: 0.1077, train_acc: 0.9485, val_acc:0.9624\n",
      "\t\ttrain_roc: 0.9891, val_roc: 0.9935, train_auprc: 0.9889, val_auprc: 0.9938\n",
      "scheduling\n",
      "Epoch: 136 (48.0024s), train_loss: 0.1324, val_loss: 0.1051, train_acc: 0.9494, val_acc:0.9633\n",
      "\t\ttrain_roc: 0.9894, val_roc: 0.9938, train_auprc: 0.9889, val_auprc: 0.9941\n",
      "scheduling\n",
      "Epoch: 137 (47.9946s), train_loss: 0.1326, val_loss: 0.1152, train_acc: 0.9489, val_acc:0.9581\n",
      "\t\ttrain_roc: 0.9894, val_roc: 0.9925, train_auprc: 0.9890, val_auprc: 0.9929\n",
      "scheduling\n",
      "Epoch: 138 (48.0389s), train_loss: 0.1248, val_loss: 0.1006, train_acc: 0.9531, val_acc:0.9651\n",
      "\t\ttrain_roc: 0.9906, val_roc: 0.9944, train_auprc: 0.9903, val_auprc: 0.9947\n",
      "scheduling\n",
      "Epoch: 139 (48.0544s), train_loss: 0.1322, val_loss: 0.1117, train_acc: 0.9500, val_acc:0.9613\n",
      "\t\ttrain_roc: 0.9894, val_roc: 0.9934, train_auprc: 0.9892, val_auprc: 0.9937\n",
      "scheduling\n",
      "Epoch: 140 (48.0310s), train_loss: 0.1356, val_loss: 0.1008, train_acc: 0.9481, val_acc:0.9645\n",
      "\t\ttrain_roc: 0.9887, val_roc: 0.9941, train_auprc: 0.9885, val_auprc: 0.9944\n",
      "scheduling\n",
      "Epoch: 141 (47.9908s), train_loss: 0.1448, val_loss: 0.1122, train_acc: 0.9445, val_acc:0.9610\n",
      "\t\ttrain_roc: 0.9871, val_roc: 0.9930, train_auprc: 0.9867, val_auprc: 0.9934\n",
      "scheduling\n",
      "Epoch: 142 (48.0809s), train_loss: 0.1231, val_loss: 0.1119, train_acc: 0.9539, val_acc:0.9592\n",
      "\t\ttrain_roc: 0.9910, val_roc: 0.9927, train_auprc: 0.9910, val_auprc: 0.9931\n",
      "scheduling\n",
      "Epoch: 143 (48.0213s), train_loss: 0.1284, val_loss: 0.1030, train_acc: 0.9513, val_acc:0.9647\n",
      "\t\ttrain_roc: 0.9899, val_roc: 0.9938, train_auprc: 0.9894, val_auprc: 0.9942\n",
      "scheduling\n",
      "Epoch: 144 (48.0020s), train_loss: 0.1234, val_loss: 0.1099, train_acc: 0.9535, val_acc:0.9612\n",
      "\t\ttrain_roc: 0.9908, val_roc: 0.9931, train_auprc: 0.9906, val_auprc: 0.9934\n",
      "scheduling\n",
      "Epoch: 145 (48.0200s), train_loss: 0.1194, val_loss: 0.1088, train_acc: 0.9557, val_acc:0.9623\n",
      "\t\ttrain_roc: 0.9914, val_roc: 0.9930, train_auprc: 0.9912, val_auprc: 0.9933\n",
      "scheduling\n",
      "Epoch: 146 (48.0286s), train_loss: 0.1166, val_loss: 0.1020, train_acc: 0.9562, val_acc:0.9644\n",
      "\t\ttrain_roc: 0.9918, val_roc: 0.9942, train_auprc: 0.9914, val_auprc: 0.9945\n",
      "scheduling\n",
      "Epoch: 147 (48.0233s), train_loss: 0.1234, val_loss: 0.1008, train_acc: 0.9530, val_acc:0.9656\n",
      "\t\ttrain_roc: 0.9907, val_roc: 0.9953, train_auprc: 0.9903, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 148 (48.0372s), train_loss: 0.1345, val_loss: 0.1009, train_acc: 0.9483, val_acc:0.9656\n",
      "\t\ttrain_roc: 0.9889, val_roc: 0.9950, train_auprc: 0.9887, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 149 (48.0242s), train_loss: 0.1210, val_loss: 0.0940, train_acc: 0.9548, val_acc:0.9684\n",
      "\t\ttrain_roc: 0.9911, val_roc: 0.9954, train_auprc: 0.9909, val_auprc: 0.9957\n",
      "scheduling\n",
      "Epoch: 150 (48.0303s), train_loss: 0.1250, val_loss: 0.1009, train_acc: 0.9525, val_acc:0.9658\n",
      "\t\ttrain_roc: 0.9905, val_roc: 0.9948, train_auprc: 0.9902, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 151 (48.1665s), train_loss: 0.1171, val_loss: 0.0923, train_acc: 0.9567, val_acc:0.9688\n",
      "\t\ttrain_roc: 0.9917, val_roc: 0.9952, train_auprc: 0.9915, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 152 (48.3364s), train_loss: 0.1188, val_loss: 0.0943, train_acc: 0.9554, val_acc:0.9684\n",
      "\t\ttrain_roc: 0.9914, val_roc: 0.9949, train_auprc: 0.9911, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 153 (48.5591s), train_loss: 0.1165, val_loss: 0.0993, train_acc: 0.9568, val_acc:0.9662\n",
      "\t\ttrain_roc: 0.9918, val_roc: 0.9945, train_auprc: 0.9914, val_auprc: 0.9948\n",
      "scheduling\n",
      "Epoch: 154 (48.6915s), train_loss: 0.1102, val_loss: 0.0967, train_acc: 0.9594, val_acc:0.9673\n",
      "\t\ttrain_roc: 0.9928, val_roc: 0.9948, train_auprc: 0.9926, val_auprc: 0.9950\n",
      "scheduling\n",
      "Epoch: 155 (48.7344s), train_loss: 0.1100, val_loss: 0.0971, train_acc: 0.9595, val_acc:0.9669\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9949, train_auprc: 0.9922, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 156 (48.6656s), train_loss: 0.1095, val_loss: 0.1000, train_acc: 0.9593, val_acc:0.9663\n",
      "\t\ttrain_roc: 0.9928, val_roc: 0.9944, train_auprc: 0.9926, val_auprc: 0.9947\n",
      "scheduling\n",
      "Epoch: 157 (49.2521s), train_loss: 0.1152, val_loss: 0.0969, train_acc: 0.9577, val_acc:0.9677\n",
      "\t\ttrain_roc: 0.9918, val_roc: 0.9950, train_auprc: 0.9914, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 158 (48.9902s), train_loss: 0.1032, val_loss: 0.0985, train_acc: 0.9619, val_acc:0.9666\n",
      "\t\ttrain_roc: 0.9938, val_roc: 0.9945, train_auprc: 0.9936, val_auprc: 0.9947\n",
      "scheduling\n",
      "Epoch: 159 (48.8934s), train_loss: 0.1112, val_loss: 0.0919, train_acc: 0.9582, val_acc:0.9692\n",
      "\t\ttrain_roc: 0.9925, val_roc: 0.9951, train_auprc: 0.9922, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 160 (48.9644s), train_loss: 0.1136, val_loss: 0.0959, train_acc: 0.9574, val_acc:0.9681\n",
      "\t\ttrain_roc: 0.9921, val_roc: 0.9948, train_auprc: 0.9918, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 161 (49.0701s), train_loss: 0.1224, val_loss: 0.0953, train_acc: 0.9548, val_acc:0.9680\n",
      "\t\ttrain_roc: 0.9906, val_roc: 0.9949, train_auprc: 0.9897, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 162 (48.9328s), train_loss: 0.1134, val_loss: 0.0921, train_acc: 0.9577, val_acc:0.9685\n",
      "\t\ttrain_roc: 0.9922, val_roc: 0.9952, train_auprc: 0.9920, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 163 (49.0225s), train_loss: 0.1185, val_loss: 0.0932, train_acc: 0.9558, val_acc:0.9684\n",
      "\t\ttrain_roc: 0.9913, val_roc: 0.9950, train_auprc: 0.9910, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 164 (48.7225s), train_loss: 0.1229, val_loss: 0.0968, train_acc: 0.9534, val_acc:0.9670\n",
      "\t\ttrain_roc: 0.9907, val_roc: 0.9947, train_auprc: 0.9903, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 165 (48.6965s), train_loss: 0.1125, val_loss: 0.0891, train_acc: 0.9580, val_acc:0.9709\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9954, train_auprc: 0.9919, val_auprc: 0.9958\n",
      "scheduling\n",
      "Epoch: 166 (49.0773s), train_loss: 0.1160, val_loss: 0.0963, train_acc: 0.9572, val_acc:0.9677\n",
      "\t\ttrain_roc: 0.9917, val_roc: 0.9950, train_auprc: 0.9911, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 167 (49.0201s), train_loss: 0.1214, val_loss: 0.0964, train_acc: 0.9544, val_acc:0.9675\n",
      "\t\ttrain_roc: 0.9909, val_roc: 0.9949, train_auprc: 0.9904, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 168 (47.9874s), train_loss: 0.1159, val_loss: 0.0919, train_acc: 0.9569, val_acc:0.9693\n",
      "\t\ttrain_roc: 0.9917, val_roc: 0.9953, train_auprc: 0.9913, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 169 (49.0589s), train_loss: 0.1083, val_loss: 0.0905, train_acc: 0.9602, val_acc:0.9698\n",
      "\t\ttrain_roc: 0.9929, val_roc: 0.9954, train_auprc: 0.9927, val_auprc: 0.9958\n",
      "scheduling\n",
      "Epoch: 170 (48.9950s), train_loss: 0.1102, val_loss: 0.0971, train_acc: 0.9592, val_acc:0.9670\n",
      "\t\ttrain_roc: 0.9927, val_roc: 0.9947, train_auprc: 0.9923, val_auprc: 0.9950\n",
      "scheduling\n",
      "Epoch: 171 (49.0297s), train_loss: 0.1197, val_loss: 0.0996, train_acc: 0.9550, val_acc:0.9656\n",
      "\t\ttrain_roc: 0.9912, val_roc: 0.9944, train_auprc: 0.9910, val_auprc: 0.9948\n",
      "scheduling\n",
      "Epoch: 172 (50.2455s), train_loss: 0.1141, val_loss: 0.1079, train_acc: 0.9576, val_acc:0.9624\n",
      "\t\ttrain_roc: 0.9920, val_roc: 0.9932, train_auprc: 0.9918, val_auprc: 0.9935\n",
      "scheduling\n",
      "Epoch: 173 (49.5398s), train_loss: 0.1089, val_loss: 0.0963, train_acc: 0.9599, val_acc:0.9676\n",
      "\t\ttrain_roc: 0.9928, val_roc: 0.9948, train_auprc: 0.9923, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 174 (48.8574s), train_loss: 0.1074, val_loss: 0.0932, train_acc: 0.9605, val_acc:0.9687\n",
      "\t\ttrain_roc: 0.9931, val_roc: 0.9949, train_auprc: 0.9929, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 175 (49.3990s), train_loss: 0.1148, val_loss: 0.0933, train_acc: 0.9572, val_acc:0.9692\n",
      "\t\ttrain_roc: 0.9921, val_roc: 0.9956, train_auprc: 0.9917, val_auprc: 0.9959\n",
      "scheduling\n",
      "Epoch: 176 (48.8488s), train_loss: 0.1210, val_loss: 0.0890, train_acc: 0.9552, val_acc:0.9709\n",
      "\t\ttrain_roc: 0.9908, val_roc: 0.9957, train_auprc: 0.9903, val_auprc: 0.9960\n",
      "scheduling\n",
      "Epoch: 177 (48.8213s), train_loss: 0.1113, val_loss: 0.1040, train_acc: 0.9590, val_acc:0.9633\n",
      "\t\ttrain_roc: 0.9925, val_roc: 0.9937, train_auprc: 0.9922, val_auprc: 0.9940\n",
      "scheduling\n",
      "Epoch: 178 (48.8118s), train_loss: 0.1088, val_loss: 0.0981, train_acc: 0.9596, val_acc:0.9657\n",
      "\t\ttrain_roc: 0.9928, val_roc: 0.9943, train_auprc: 0.9928, val_auprc: 0.9945\n",
      "scheduling\n",
      "Epoch: 179 (48.8567s), train_loss: 0.1147, val_loss: 0.1028, train_acc: 0.9567, val_acc:0.9644\n",
      "\t\ttrain_roc: 0.9919, val_roc: 0.9938, train_auprc: 0.9917, val_auprc: 0.9942\n",
      "scheduling\n",
      "Epoch: 180 (48.7110s), train_loss: 0.1162, val_loss: 0.0924, train_acc: 0.9566, val_acc:0.9700\n",
      "\t\ttrain_roc: 0.9917, val_roc: 0.9953, train_auprc: 0.9916, val_auprc: 0.9957\n",
      "scheduling\n",
      "Epoch: 181 (48.7347s), train_loss: 0.1155, val_loss: 0.1022, train_acc: 0.9569, val_acc:0.9653\n",
      "\t\ttrain_roc: 0.9919, val_roc: 0.9941, train_auprc: 0.9915, val_auprc: 0.9944\n",
      "scheduling\n",
      "Epoch: 182 (48.6194s), train_loss: 0.1111, val_loss: 0.0938, train_acc: 0.9589, val_acc:0.9694\n",
      "\t\ttrain_roc: 0.9925, val_roc: 0.9951, train_auprc: 0.9921, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 183 (48.5812s), train_loss: 0.1119, val_loss: 0.0943, train_acc: 0.9582, val_acc:0.9688\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9949, train_auprc: 0.9919, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 184 (48.6973s), train_loss: 0.1103, val_loss: 0.0943, train_acc: 0.9589, val_acc:0.9685\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9951, train_auprc: 0.9924, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 185 (48.6647s), train_loss: 0.1145, val_loss: 0.0900, train_acc: 0.9571, val_acc:0.9709\n",
      "\t\ttrain_roc: 0.9919, val_roc: 0.9955, train_auprc: 0.9916, val_auprc: 0.9958\n",
      "scheduling\n",
      "Epoch: 186 (49.2429s), train_loss: 0.1103, val_loss: 0.0938, train_acc: 0.9593, val_acc:0.9692\n",
      "\t\ttrain_roc: 0.9925, val_roc: 0.9951, train_auprc: 0.9921, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 187 (49.2305s), train_loss: 0.1083, val_loss: 0.0869, train_acc: 0.9598, val_acc:0.9721\n",
      "\t\ttrain_roc: 0.9929, val_roc: 0.9960, train_auprc: 0.9926, val_auprc: 0.9963\n",
      "scheduling\n",
      "Epoch: 188 (48.9857s), train_loss: 0.1127, val_loss: 0.0929, train_acc: 0.9580, val_acc:0.9689\n",
      "\t\ttrain_roc: 0.9922, val_roc: 0.9950, train_auprc: 0.9919, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 189 (48.9262s), train_loss: 0.1025, val_loss: 0.1014, train_acc: 0.9619, val_acc:0.9651\n",
      "\t\ttrain_roc: 0.9939, val_roc: 0.9940, train_auprc: 0.9938, val_auprc: 0.9944\n",
      "scheduling\n",
      "Epoch: 190 (48.7540s), train_loss: 0.1096, val_loss: 0.0896, train_acc: 0.9597, val_acc:0.9713\n",
      "\t\ttrain_roc: 0.9927, val_roc: 0.9956, train_auprc: 0.9923, val_auprc: 0.9960\n",
      "scheduling\n",
      "Epoch: 191 (49.0569s), train_loss: 0.1112, val_loss: 0.0952, train_acc: 0.9590, val_acc:0.9687\n",
      "\t\ttrain_roc: 0.9924, val_roc: 0.9948, train_auprc: 0.9921, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 192 (48.8475s), train_loss: 0.1102, val_loss: 0.0919, train_acc: 0.9591, val_acc:0.9698\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9952, train_auprc: 0.9924, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 193 (48.9364s), train_loss: 0.1083, val_loss: 0.0925, train_acc: 0.9596, val_acc:0.9689\n",
      "\t\ttrain_roc: 0.9929, val_roc: 0.9953, train_auprc: 0.9926, val_auprc: 0.9957\n",
      "scheduling\n",
      "Epoch: 194 (48.8253s), train_loss: 0.1096, val_loss: 0.0961, train_acc: 0.9593, val_acc:0.9677\n",
      "\t\ttrain_roc: 0.9927, val_roc: 0.9947, train_auprc: 0.9924, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 195 (48.7463s), train_loss: 0.1087, val_loss: 0.0994, train_acc: 0.9597, val_acc:0.9662\n",
      "\t\ttrain_roc: 0.9929, val_roc: 0.9942, train_auprc: 0.9926, val_auprc: 0.9947\n",
      "scheduling\n",
      "Epoch: 196 (48.7106s), train_loss: 0.1020, val_loss: 0.0963, train_acc: 0.9626, val_acc:0.9678\n",
      "\t\ttrain_roc: 0.9938, val_roc: 0.9946, train_auprc: 0.9936, val_auprc: 0.9950\n",
      "scheduling\n",
      "Epoch: 197 (48.6587s), train_loss: 0.1059, val_loss: 0.0950, train_acc: 0.9610, val_acc:0.9678\n",
      "\t\ttrain_roc: 0.9933, val_roc: 0.9950, train_auprc: 0.9931, val_auprc: 0.9954\n",
      "scheduling\n",
      "Epoch: 198 (48.8136s), train_loss: 0.1037, val_loss: 0.0988, train_acc: 0.9614, val_acc:0.9665\n",
      "\t\ttrain_roc: 0.9936, val_roc: 0.9944, train_auprc: 0.9934, val_auprc: 0.9949\n",
      "scheduling\n",
      "Epoch: 199 (48.7223s), train_loss: 0.1047, val_loss: 0.0918, train_acc: 0.9611, val_acc:0.9694\n",
      "\t\ttrain_roc: 0.9934, val_roc: 0.9951, train_auprc: 0.9934, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 200 (48.6146s), train_loss: 0.1127, val_loss: 0.0961, train_acc: 0.9574, val_acc:0.9671\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9947, train_auprc: 0.9922, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 201 (48.5698s), train_loss: 0.1102, val_loss: 0.0951, train_acc: 0.9590, val_acc:0.9682\n",
      "\t\ttrain_roc: 0.9927, val_roc: 0.9949, train_auprc: 0.9925, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 202 (48.6457s), train_loss: 0.1072, val_loss: 0.1024, train_acc: 0.9600, val_acc:0.9651\n",
      "\t\ttrain_roc: 0.9931, val_roc: 0.9938, train_auprc: 0.9930, val_auprc: 0.9942\n",
      "scheduling\n",
      "Epoch: 203 (48.5810s), train_loss: 0.0978, val_loss: 0.0994, train_acc: 0.9648, val_acc:0.9660\n",
      "\t\ttrain_roc: 0.9944, val_roc: 0.9941, train_auprc: 0.9943, val_auprc: 0.9944\n",
      "scheduling\n",
      "Epoch: 204 (48.5945s), train_loss: 0.1038, val_loss: 0.0978, train_acc: 0.9617, val_acc:0.9667\n",
      "\t\ttrain_roc: 0.9935, val_roc: 0.9945, train_auprc: 0.9932, val_auprc: 0.9950\n",
      "scheduling\n",
      "Epoch: 205 (48.5976s), train_loss: 0.1149, val_loss: 0.0936, train_acc: 0.9576, val_acc:0.9688\n",
      "\t\ttrain_roc: 0.9917, val_roc: 0.9952, train_auprc: 0.9909, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 206 (48.7352s), train_loss: 0.1037, val_loss: 0.0899, train_acc: 0.9622, val_acc:0.9696\n",
      "\t\ttrain_roc: 0.9936, val_roc: 0.9955, train_auprc: 0.9934, val_auprc: 0.9959\n",
      "scheduling\n",
      "Epoch: 207 (48.6359s), train_loss: 0.1139, val_loss: 0.0966, train_acc: 0.9572, val_acc:0.9671\n",
      "\t\ttrain_roc: 0.9920, val_roc: 0.9946, train_auprc: 0.9919, val_auprc: 0.9950\n",
      "scheduling\n",
      "Epoch: 208 (48.7169s), train_loss: 0.1226, val_loss: 0.0954, train_acc: 0.9536, val_acc:0.9680\n",
      "\t\ttrain_roc: 0.9907, val_roc: 0.9949, train_auprc: 0.9904, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 209 (48.6565s), train_loss: 0.1137, val_loss: 0.0953, train_acc: 0.9581, val_acc:0.9678\n",
      "\t\ttrain_roc: 0.9920, val_roc: 0.9948, train_auprc: 0.9916, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 210 (48.7632s), train_loss: 0.1073, val_loss: 0.0887, train_acc: 0.9603, val_acc:0.9705\n",
      "\t\ttrain_roc: 0.9930, val_roc: 0.9958, train_auprc: 0.9928, val_auprc: 0.9962\n",
      "scheduling\n",
      "Epoch: 211 (48.7192s), train_loss: 0.1210, val_loss: 0.0948, train_acc: 0.9541, val_acc:0.9679\n",
      "\t\ttrain_roc: 0.9909, val_roc: 0.9951, train_auprc: 0.9904, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 212 (48.7867s), train_loss: 0.1004, val_loss: 0.0920, train_acc: 0.9632, val_acc:0.9699\n",
      "\t\ttrain_roc: 0.9940, val_roc: 0.9953, train_auprc: 0.9938, val_auprc: 0.9957\n",
      "scheduling\n",
      "Epoch: 213 (48.7491s), train_loss: 0.1195, val_loss: 0.0986, train_acc: 0.9552, val_acc:0.9662\n",
      "\t\ttrain_roc: 0.9912, val_roc: 0.9944, train_auprc: 0.9908, val_auprc: 0.9948\n",
      "scheduling\n",
      "Epoch: 214 (48.7309s), train_loss: 0.1131, val_loss: 0.0974, train_acc: 0.9578, val_acc:0.9669\n",
      "\t\ttrain_roc: 0.9921, val_roc: 0.9947, train_auprc: 0.9918, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 215 (48.7888s), train_loss: 0.1101, val_loss: 0.0921, train_acc: 0.9590, val_acc:0.9696\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9953, train_auprc: 0.9923, val_auprc: 0.9957\n",
      "scheduling\n",
      "Epoch: 216 (48.7543s), train_loss: 0.1125, val_loss: 0.0936, train_acc: 0.9584, val_acc:0.9688\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9951, train_auprc: 0.9921, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 217 (48.6599s), train_loss: 0.1088, val_loss: 0.1020, train_acc: 0.9595, val_acc:0.9652\n",
      "\t\ttrain_roc: 0.9929, val_roc: 0.9940, train_auprc: 0.9928, val_auprc: 0.9944\n",
      "scheduling\n",
      "Epoch: 218 (48.7746s), train_loss: 0.1098, val_loss: 0.0969, train_acc: 0.9592, val_acc:0.9674\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9946, train_auprc: 0.9924, val_auprc: 0.9950\n",
      "scheduling\n",
      "Epoch: 219 (48.6869s), train_loss: 0.1109, val_loss: 0.1025, train_acc: 0.9585, val_acc:0.9649\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9939, train_auprc: 0.9924, val_auprc: 0.9944\n",
      "scheduling\n",
      "Epoch: 220 (48.8480s), train_loss: 0.1192, val_loss: 0.0926, train_acc: 0.9543, val_acc:0.9689\n",
      "\t\ttrain_roc: 0.9913, val_roc: 0.9953, train_auprc: 0.9911, val_auprc: 0.9957\n",
      "scheduling\n",
      "Epoch: 221 (48.7806s), train_loss: 0.1141, val_loss: 0.0957, train_acc: 0.9578, val_acc:0.9678\n",
      "\t\ttrain_roc: 0.9920, val_roc: 0.9950, train_auprc: 0.9916, val_auprc: 0.9954\n",
      "scheduling\n",
      "Epoch: 222 (48.4410s), train_loss: 0.1115, val_loss: 0.1061, train_acc: 0.9578, val_acc:0.9624\n",
      "\t\ttrain_roc: 0.9925, val_roc: 0.9933, train_auprc: 0.9924, val_auprc: 0.9935\n",
      "scheduling\n",
      "Epoch: 223 (48.6365s), train_loss: 0.1179, val_loss: 0.0982, train_acc: 0.9558, val_acc:0.9667\n",
      "\t\ttrain_roc: 0.9914, val_roc: 0.9945, train_auprc: 0.9908, val_auprc: 0.9949\n",
      "scheduling\n",
      "Epoch: 224 (48.6618s), train_loss: 0.1112, val_loss: 0.0994, train_acc: 0.9585, val_acc:0.9662\n",
      "\t\ttrain_roc: 0.9925, val_roc: 0.9943, train_auprc: 0.9922, val_auprc: 0.9946\n",
      "scheduling\n",
      "Epoch: 225 (48.8390s), train_loss: 0.1102, val_loss: 0.0948, train_acc: 0.9585, val_acc:0.9682\n",
      "\t\ttrain_roc: 0.9927, val_roc: 0.9950, train_auprc: 0.9924, val_auprc: 0.9954\n",
      "scheduling\n",
      "Epoch: 226 (48.7312s), train_loss: 0.1187, val_loss: 0.0958, train_acc: 0.9556, val_acc:0.9677\n",
      "\t\ttrain_roc: 0.9914, val_roc: 0.9949, train_auprc: 0.9909, val_auprc: 0.9954\n",
      "scheduling\n",
      "Epoch: 227 (48.8664s), train_loss: 0.1130, val_loss: 0.1066, train_acc: 0.9576, val_acc:0.9631\n",
      "\t\ttrain_roc: 0.9922, val_roc: 0.9934, train_auprc: 0.9919, val_auprc: 0.9939\n",
      "scheduling\n",
      "Epoch: 228 (49.1711s), train_loss: 0.1165, val_loss: 0.0935, train_acc: 0.9561, val_acc:0.9688\n",
      "\t\ttrain_roc: 0.9917, val_roc: 0.9953, train_auprc: 0.9914, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 229 (48.7488s), train_loss: 0.1210, val_loss: 0.0959, train_acc: 0.9542, val_acc:0.9672\n",
      "\t\ttrain_roc: 0.9910, val_roc: 0.9949, train_auprc: 0.9909, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 230 (48.7515s), train_loss: 0.1113, val_loss: 0.0974, train_acc: 0.9586, val_acc:0.9666\n",
      "\t\ttrain_roc: 0.9924, val_roc: 0.9946, train_auprc: 0.9921, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 231 (48.9680s), train_loss: 0.1073, val_loss: 0.0972, train_acc: 0.9600, val_acc:0.9672\n",
      "\t\ttrain_roc: 0.9930, val_roc: 0.9946, train_auprc: 0.9927, val_auprc: 0.9950\n",
      "scheduling\n",
      "Epoch: 232 (48.9919s), train_loss: 0.1124, val_loss: 0.0993, train_acc: 0.9580, val_acc:0.9658\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9944, train_auprc: 0.9921, val_auprc: 0.9948\n",
      "scheduling\n",
      "Epoch: 233 (49.0407s), train_loss: 0.1103, val_loss: 0.0948, train_acc: 0.9587, val_acc:0.9685\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9950, train_auprc: 0.9922, val_auprc: 0.9954\n",
      "scheduling\n",
      "Epoch: 234 (48.8038s), train_loss: 0.1108, val_loss: 0.0950, train_acc: 0.9586, val_acc:0.9682\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9950, train_auprc: 0.9923, val_auprc: 0.9954\n",
      "scheduling\n",
      "Epoch: 235 (48.7265s), train_loss: 0.1094, val_loss: 0.0984, train_acc: 0.9588, val_acc:0.9668\n",
      "\t\ttrain_roc: 0.9928, val_roc: 0.9944, train_auprc: 0.9927, val_auprc: 0.9948\n",
      "scheduling\n",
      "Epoch: 236 (48.8521s), train_loss: 0.1267, val_loss: 0.0905, train_acc: 0.9524, val_acc:0.9702\n",
      "\t\ttrain_roc: 0.9900, val_roc: 0.9955, train_auprc: 0.9896, val_auprc: 0.9959\n",
      "scheduling\n",
      "Epoch: 237 (48.7314s), train_loss: 0.1094, val_loss: 0.1010, train_acc: 0.9588, val_acc:0.9654\n",
      "\t\ttrain_roc: 0.9928, val_roc: 0.9941, train_auprc: 0.9926, val_auprc: 0.9946\n",
      "scheduling\n",
      "Epoch: 238 (48.6861s), train_loss: 0.1107, val_loss: 0.0910, train_acc: 0.9581, val_acc:0.9698\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9955, train_auprc: 0.9924, val_auprc: 0.9959\n",
      "scheduling\n",
      "Epoch: 239 (48.5798s), train_loss: 0.1114, val_loss: 0.0928, train_acc: 0.9589, val_acc:0.9693\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9953, train_auprc: 0.9918, val_auprc: 0.9957\n",
      "scheduling\n",
      "Epoch: 240 (48.5665s), train_loss: 0.1005, val_loss: 0.0923, train_acc: 0.9632, val_acc:0.9693\n",
      "\t\ttrain_roc: 0.9940, val_roc: 0.9952, train_auprc: 0.9939, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 241 (49.0683s), train_loss: 0.1154, val_loss: 0.0928, train_acc: 0.9566, val_acc:0.9690\n",
      "\t\ttrain_roc: 0.9918, val_roc: 0.9952, train_auprc: 0.9914, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 242 (48.8937s), train_loss: 0.1176, val_loss: 0.0989, train_acc: 0.9562, val_acc:0.9665\n",
      "\t\ttrain_roc: 0.9914, val_roc: 0.9945, train_auprc: 0.9910, val_auprc: 0.9949\n",
      "scheduling\n",
      "Epoch: 243 (48.8061s), train_loss: 0.1158, val_loss: 0.0972, train_acc: 0.9575, val_acc:0.9669\n",
      "\t\ttrain_roc: 0.9917, val_roc: 0.9947, train_auprc: 0.9911, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 244 (48.8274s), train_loss: 0.1234, val_loss: 0.0933, train_acc: 0.9544, val_acc:0.9689\n",
      "\t\ttrain_roc: 0.9904, val_roc: 0.9953, train_auprc: 0.9897, val_auprc: 0.9957\n",
      "scheduling\n",
      "Epoch: 245 (48.8960s), train_loss: 0.1105, val_loss: 0.0948, train_acc: 0.9589, val_acc:0.9685\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9950, train_auprc: 0.9923, val_auprc: 0.9954\n",
      "scheduling\n",
      "Epoch: 246 (48.6613s), train_loss: 0.1125, val_loss: 0.0892, train_acc: 0.9582, val_acc:0.9709\n",
      "\t\ttrain_roc: 0.9922, val_roc: 0.9958, train_auprc: 0.9916, val_auprc: 0.9962\n",
      "scheduling\n",
      "Epoch: 247 (48.7742s), train_loss: 0.1183, val_loss: 0.0899, train_acc: 0.9554, val_acc:0.9704\n",
      "\t\ttrain_roc: 0.9914, val_roc: 0.9957, train_auprc: 0.9911, val_auprc: 0.9961\n",
      "scheduling\n",
      "Epoch: 248 (48.7220s), train_loss: 0.1102, val_loss: 0.0944, train_acc: 0.9592, val_acc:0.9682\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9951, train_auprc: 0.9922, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 249 (48.7045s), train_loss: 0.1104, val_loss: 0.1005, train_acc: 0.9589, val_acc:0.9658\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9942, train_auprc: 0.9923, val_auprc: 0.9946\n",
      "scheduling\n",
      "Epoch: 250 (48.9000s), train_loss: 0.1260, val_loss: 0.0968, train_acc: 0.9528, val_acc:0.9671\n",
      "\t\ttrain_roc: 0.9901, val_roc: 0.9946, train_auprc: 0.9898, val_auprc: 0.9949\n",
      "scheduling\n",
      "Epoch: 251 (48.7085s), train_loss: 0.1094, val_loss: 0.1011, train_acc: 0.9590, val_acc:0.9648\n",
      "\t\ttrain_roc: 0.9928, val_roc: 0.9940, train_auprc: 0.9928, val_auprc: 0.9944\n",
      "scheduling\n",
      "Epoch: 252 (48.6648s), train_loss: 0.1119, val_loss: 0.0955, train_acc: 0.9580, val_acc:0.9684\n",
      "\t\ttrain_roc: 0.9924, val_roc: 0.9948, train_auprc: 0.9921, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 253 (48.6514s), train_loss: 0.1136, val_loss: 0.0944, train_acc: 0.9577, val_acc:0.9682\n",
      "\t\ttrain_roc: 0.9922, val_roc: 0.9950, train_auprc: 0.9919, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 254 (48.6219s), train_loss: 0.1073, val_loss: 0.0932, train_acc: 0.9603, val_acc:0.9687\n",
      "\t\ttrain_roc: 0.9930, val_roc: 0.9952, train_auprc: 0.9928, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 255 (48.6375s), train_loss: 0.1118, val_loss: 0.0923, train_acc: 0.9585, val_acc:0.9693\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9953, train_auprc: 0.9920, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 256 (48.6732s), train_loss: 0.1173, val_loss: 0.0954, train_acc: 0.9561, val_acc:0.9677\n",
      "\t\ttrain_roc: 0.9915, val_roc: 0.9949, train_auprc: 0.9914, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 257 (48.7379s), train_loss: 0.1173, val_loss: 0.1026, train_acc: 0.9556, val_acc:0.9646\n",
      "\t\ttrain_roc: 0.9915, val_roc: 0.9938, train_auprc: 0.9910, val_auprc: 0.9942\n",
      "scheduling\n",
      "Epoch: 258 (48.7654s), train_loss: 0.1075, val_loss: 0.0960, train_acc: 0.9598, val_acc:0.9681\n",
      "\t\ttrain_roc: 0.9931, val_roc: 0.9948, train_auprc: 0.9928, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 259 (48.8166s), train_loss: 0.1099, val_loss: 0.0918, train_acc: 0.9595, val_acc:0.9695\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9953, train_auprc: 0.9921, val_auprc: 0.9957\n",
      "scheduling\n",
      "Epoch: 260 (48.5727s), train_loss: 0.1052, val_loss: 0.0981, train_acc: 0.9609, val_acc:0.9670\n",
      "\t\ttrain_roc: 0.9933, val_roc: 0.9945, train_auprc: 0.9931, val_auprc: 0.9949\n",
      "scheduling\n",
      "Epoch: 261 (48.5694s), train_loss: 0.1052, val_loss: 0.0937, train_acc: 0.9613, val_acc:0.9689\n",
      "\t\ttrain_roc: 0.9934, val_roc: 0.9951, train_auprc: 0.9932, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 262 (48.5332s), train_loss: 0.1190, val_loss: 0.0983, train_acc: 0.9549, val_acc:0.9665\n",
      "\t\ttrain_roc: 0.9913, val_roc: 0.9945, train_auprc: 0.9908, val_auprc: 0.9949\n",
      "scheduling\n",
      "Epoch: 263 (48.6205s), train_loss: 0.1044, val_loss: 0.0937, train_acc: 0.9618, val_acc:0.9688\n",
      "\t\ttrain_roc: 0.9934, val_roc: 0.9950, train_auprc: 0.9932, val_auprc: 0.9954\n",
      "scheduling\n",
      "Epoch: 264 (48.6397s), train_loss: 0.1095, val_loss: 0.0885, train_acc: 0.9595, val_acc:0.9709\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9957, train_auprc: 0.9922, val_auprc: 0.9961\n",
      "scheduling\n",
      "Epoch: 265 (48.6303s), train_loss: 0.1083, val_loss: 0.0961, train_acc: 0.9591, val_acc:0.9679\n",
      "\t\ttrain_roc: 0.9929, val_roc: 0.9947, train_auprc: 0.9928, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 266 (48.6582s), train_loss: 0.1142, val_loss: 0.1013, train_acc: 0.9572, val_acc:0.9651\n",
      "\t\ttrain_roc: 0.9922, val_roc: 0.9940, train_auprc: 0.9919, val_auprc: 0.9945\n",
      "scheduling\n",
      "Epoch: 267 (48.5659s), train_loss: 0.1082, val_loss: 0.0909, train_acc: 0.9594, val_acc:0.9695\n",
      "\t\ttrain_roc: 0.9929, val_roc: 0.9955, train_auprc: 0.9927, val_auprc: 0.9959\n",
      "scheduling\n",
      "Epoch: 268 (48.8366s), train_loss: 0.1119, val_loss: 0.0939, train_acc: 0.9586, val_acc:0.9681\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9950, train_auprc: 0.9922, val_auprc: 0.9954\n",
      "scheduling\n",
      "Epoch: 269 (48.6889s), train_loss: 0.1126, val_loss: 0.0968, train_acc: 0.9577, val_acc:0.9670\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9947, train_auprc: 0.9923, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 270 (48.8587s), train_loss: 0.1059, val_loss: 0.0925, train_acc: 0.9606, val_acc:0.9690\n",
      "\t\ttrain_roc: 0.9933, val_roc: 0.9952, train_auprc: 0.9932, val_auprc: 0.9957\n",
      "scheduling\n",
      "Epoch: 271 (48.8913s), train_loss: 0.1109, val_loss: 0.0898, train_acc: 0.9593, val_acc:0.9700\n",
      "\t\ttrain_roc: 0.9924, val_roc: 0.9956, train_auprc: 0.9919, val_auprc: 0.9960\n",
      "scheduling\n",
      "Epoch: 272 (48.7539s), train_loss: 0.1208, val_loss: 0.0938, train_acc: 0.9549, val_acc:0.9682\n",
      "\t\ttrain_roc: 0.9910, val_roc: 0.9951, train_auprc: 0.9906, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 273 (48.7395s), train_loss: 0.1034, val_loss: 0.0998, train_acc: 0.9615, val_acc:0.9652\n",
      "\t\ttrain_roc: 0.9936, val_roc: 0.9942, train_auprc: 0.9933, val_auprc: 0.9946\n",
      "scheduling\n",
      "Epoch: 274 (48.6963s), train_loss: 0.1124, val_loss: 0.0950, train_acc: 0.9576, val_acc:0.9675\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9949, train_auprc: 0.9922, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 275 (48.4419s), train_loss: 0.1096, val_loss: 0.1075, train_acc: 0.9597, val_acc:0.9626\n",
      "\t\ttrain_roc: 0.9927, val_roc: 0.9932, train_auprc: 0.9923, val_auprc: 0.9936\n",
      "scheduling\n",
      "Epoch: 276 (48.5945s), train_loss: 0.1102, val_loss: 0.1048, train_acc: 0.9591, val_acc:0.9637\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9935, train_auprc: 0.9924, val_auprc: 0.9939\n",
      "scheduling\n",
      "Epoch: 277 (48.7202s), train_loss: 0.1104, val_loss: 0.0975, train_acc: 0.9592, val_acc:0.9672\n",
      "\t\ttrain_roc: 0.9925, val_roc: 0.9946, train_auprc: 0.9920, val_auprc: 0.9950\n",
      "scheduling\n",
      "Epoch: 278 (48.6715s), train_loss: 0.1174, val_loss: 0.0939, train_acc: 0.9557, val_acc:0.9685\n",
      "\t\ttrain_roc: 0.9916, val_roc: 0.9950, train_auprc: 0.9914, val_auprc: 0.9954\n",
      "scheduling\n",
      "Epoch: 279 (48.7240s), train_loss: 0.1100, val_loss: 0.0982, train_acc: 0.9593, val_acc:0.9665\n",
      "\t\ttrain_roc: 0.9926, val_roc: 0.9944, train_auprc: 0.9922, val_auprc: 0.9948\n",
      "scheduling\n",
      "Epoch: 280 (48.7910s), train_loss: 0.1051, val_loss: 0.0910, train_acc: 0.9611, val_acc:0.9694\n",
      "\t\ttrain_roc: 0.9933, val_roc: 0.9954, train_auprc: 0.9929, val_auprc: 0.9958\n",
      "scheduling\n",
      "Epoch: 281 (48.8154s), train_loss: 0.1142, val_loss: 0.0964, train_acc: 0.9575, val_acc:0.9671\n",
      "\t\ttrain_roc: 0.9920, val_roc: 0.9947, train_auprc: 0.9918, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 282 (48.7442s), train_loss: 0.1179, val_loss: 0.1018, train_acc: 0.9559, val_acc:0.9646\n",
      "\t\ttrain_roc: 0.9914, val_roc: 0.9940, train_auprc: 0.9910, val_auprc: 0.9945\n",
      "scheduling\n",
      "Epoch: 283 (48.8654s), train_loss: 0.1025, val_loss: 0.0943, train_acc: 0.9622, val_acc:0.9683\n",
      "\t\ttrain_roc: 0.9937, val_roc: 0.9949, train_auprc: 0.9935, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 284 (48.6063s), train_loss: 0.1187, val_loss: 0.0983, train_acc: 0.9557, val_acc:0.9666\n",
      "\t\ttrain_roc: 0.9913, val_roc: 0.9945, train_auprc: 0.9911, val_auprc: 0.9950\n",
      "scheduling\n",
      "Epoch: 285 (48.8621s), train_loss: 0.1194, val_loss: 0.0928, train_acc: 0.9556, val_acc:0.9693\n",
      "\t\ttrain_roc: 0.9911, val_roc: 0.9951, train_auprc: 0.9907, val_auprc: 0.9954\n",
      "scheduling\n",
      "Epoch: 286 (48.8966s), train_loss: 0.1080, val_loss: 0.1010, train_acc: 0.9596, val_acc:0.9650\n",
      "\t\ttrain_roc: 0.9930, val_roc: 0.9941, train_auprc: 0.9931, val_auprc: 0.9945\n",
      "scheduling\n",
      "Epoch: 287 (48.7132s), train_loss: 0.1114, val_loss: 0.0981, train_acc: 0.9591, val_acc:0.9661\n",
      "\t\ttrain_roc: 0.9922, val_roc: 0.9945, train_auprc: 0.9917, val_auprc: 0.9949\n",
      "scheduling\n",
      "Epoch: 288 (48.8594s), train_loss: 0.1124, val_loss: 0.0926, train_acc: 0.9584, val_acc:0.9693\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9952, train_auprc: 0.9919, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 289 (48.6926s), train_loss: 0.1050, val_loss: 0.0926, train_acc: 0.9612, val_acc:0.9692\n",
      "\t\ttrain_roc: 0.9933, val_roc: 0.9952, train_auprc: 0.9929, val_auprc: 0.9956\n",
      "scheduling\n",
      "Epoch: 290 (48.7236s), train_loss: 0.1177, val_loss: 0.0938, train_acc: 0.9562, val_acc:0.9686\n",
      "\t\ttrain_roc: 0.9914, val_roc: 0.9951, train_auprc: 0.9911, val_auprc: 0.9955\n",
      "scheduling\n",
      "Epoch: 291 (48.9310s), train_loss: 0.1097, val_loss: 0.1027, train_acc: 0.9592, val_acc:0.9645\n",
      "\t\ttrain_roc: 0.9927, val_roc: 0.9938, train_auprc: 0.9924, val_auprc: 0.9942\n",
      "scheduling\n",
      "Epoch: 292 (48.5442s), train_loss: 0.1174, val_loss: 0.0953, train_acc: 0.9562, val_acc:0.9680\n",
      "\t\ttrain_roc: 0.9915, val_roc: 0.9949, train_auprc: 0.9911, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 293 (48.5234s), train_loss: 0.1080, val_loss: 0.0960, train_acc: 0.9598, val_acc:0.9674\n",
      "\t\ttrain_roc: 0.9929, val_roc: 0.9948, train_auprc: 0.9925, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 294 (48.6752s), train_loss: 0.1172, val_loss: 0.0947, train_acc: 0.9562, val_acc:0.9684\n",
      "\t\ttrain_roc: 0.9914, val_roc: 0.9949, train_auprc: 0.9908, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 295 (48.7058s), train_loss: 0.1149, val_loss: 0.0988, train_acc: 0.9574, val_acc:0.9668\n",
      "\t\ttrain_roc: 0.9918, val_roc: 0.9944, train_auprc: 0.9916, val_auprc: 0.9948\n",
      "scheduling\n",
      "Epoch: 296 (49.3313s), train_loss: 0.1174, val_loss: 0.0968, train_acc: 0.9560, val_acc:0.9670\n",
      "\t\ttrain_roc: 0.9914, val_roc: 0.9947, train_auprc: 0.9910, val_auprc: 0.9951\n",
      "scheduling\n",
      "Epoch: 297 (49.3443s), train_loss: 0.1128, val_loss: 0.1023, train_acc: 0.9577, val_acc:0.9646\n",
      "\t\ttrain_roc: 0.9923, val_roc: 0.9939, train_auprc: 0.9921, val_auprc: 0.9944\n",
      "scheduling\n",
      "Epoch: 298 (49.2218s), train_loss: 0.1051, val_loss: 0.0942, train_acc: 0.9614, val_acc:0.9684\n",
      "\t\ttrain_roc: 0.9933, val_roc: 0.9949, train_auprc: 0.9930, val_auprc: 0.9953\n",
      "scheduling\n",
      "Epoch: 299 (49.3341s), train_loss: 0.1115, val_loss: 0.0963, train_acc: 0.9576, val_acc:0.9671\n",
      "\t\ttrain_roc: 0.9925, val_roc: 0.9948, train_auprc: 0.9924, val_auprc: 0.9952\n",
      "scheduling\n",
      "Epoch: 300 (49.3780s), train_loss: 0.1095, val_loss: 0.0958, train_acc: 0.9590, val_acc:0.9680\n",
      "\t\ttrain_roc: 0.9928, val_roc: 0.9947, train_auprc: 0.9927, val_auprc: 0.9951\n"
     ]
    }
   ],
   "source": [
    "train(model, train_data_loader, val_data_loader, loss, optimizer, n_epochs, device, scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('attended-pooling-v2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4be85f8989b472e81eec2a9f752c4651e901496527f53c28cc3d62caf3c00114"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
